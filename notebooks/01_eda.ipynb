{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Load ratings + movies; check shapes, nulls, dtypes, duplicates.\n",
    "\n",
    "Basic profiles:\n",
    "\n",
    "ratings per user/movie (plots), rating distribution, sparsity %.\n",
    "\n",
    "time distribution (if timestamps available).\n",
    "\n",
    "Quick insights: top genres, most‑rated titles, long‑tail effect."
   ],
   "id": "473244be1946b8d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Exploratory Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "os.chdir(r\"C:\\Users\\Emmet\\PycharmProjects\\streaming-recs-project\")\n",
    "ratings = pd.read_csv('data/ml32/ratings.csv')\n",
    "movies = pd.read_csv('data/ml32/movies.csv')\n",
    "df = ratings.merge(movies, on='movieId', how='left')\n",
    "\n",
    "# sparsity\n",
    "n_users = df['userId'].nunique()\n",
    "n_items = df['movieId'].nunique()\n",
    "sparsity = 1 - (len(df)/ (n_users*n_items))\n",
    "\n",
    "\n",
    "#check data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram of rating values\n",
    "plt.figure(figsize=(6,4))\n",
    "df['rating'].hist(bins=10, edgecolor='black')\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Top 10 most-rated movies\n",
    "top_movies = (\n",
    "    df.groupby('title')['rating']\n",
    "      .count()\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "top_movies.plot(kind='barh')\n",
    "plt.title(\"Top 10 Most-Rated Movies\")\n",
    "plt.xlabel(\"Number of Ratings\")\n",
    "plt.gca().invert_yaxis()  # so the top movie is at the top\n",
    "plt.show()\n",
    "\n",
    "# Ratings per user\n",
    "ratings_per_user = df.groupby('userId')['rating'].count()\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.hist(ratings_per_user.clip(upper=ratings_per_user.quantile(0.98)),\n",
    "        bins=40, edgecolor='black')\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(\"Ratings per User (y=log, clipped at P98)\")\n",
    "ax.set_xlabel(\"Number of Ratings\")\n",
    "ax.set_ylabel(\"Number of Users (log scale)\")\n",
    "plt.show()\n",
    "\n",
    "# Ratings per movie\n",
    "ratings_per_movie = df.groupby('movieId')['rating'].count()\n",
    "\n",
    "cap_value = ratings_per_movie.quantile(0.98)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(ratings_per_movie.clip(upper=cap_value),\n",
    "         bins=40, edgecolor='black')\n",
    "plt.yscale('log')  # log-based y-axis\n",
    "plt.title(\"Distribution of Ratings per Movie (log y, clipped at P98)\")\n",
    "plt.xlabel(\"Number of Ratings\")\n",
    "plt.ylabel(\"Number of Movies (log scale)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#summary Table\n",
    "print(f\"Number of users: {n_users}\")\n",
    "print(f\"Number of movies: {n_items}\")\n",
    "print(f\"Number of ratings: {len(df)}\")\n",
    "print(f\"Sparsity: {sparsity:.4f}\")\n"
   ],
   "id": "686ae6d42154721b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Popularity recommender\n",
    "\n",
    "Recommend the same top-N most-rated movies to every user.\n",
    "\n",
    "Average-rating recommender: Recommend movies with the highest average rating (with a minimum rating count threshold to avoid unreliable averages).\n",
    "\n",
    "Random recommender - Just to see the “floor” performance."
   ],
   "id": "639d38e68d96872e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Popularity Recommender\n",
    "\n",
    "#Group DataFrame by movieId and count ratings.\n",
    "    #set correct path\n",
    "os.chdir(r\"C:\\Users\\Emmet\\PycharmProjects\\streaming-recs-project\")\n",
    "    #create dataframe from ratings and movies\n",
    "ratings = pd.read_csv('data/ml32/ratings.csv')\n",
    "movies = pd.read_csv('data/ml32/movies.csv')\n",
    "df = ratings.merge(movies, on='movieId', how='left')\n",
    "\n",
    "movie_count = df.groupby('movieId')['rating'].count()\n",
    "\n",
    "#sort descending by rating count.\n",
    "movie_count_sorted = movie_count.sort_values(ascending=False)\n",
    "\n",
    "#join with the movies DataFrame to get titles\n",
    "movie_count_df = movie_count_sorted.reset_index(name='num_ratings')\n",
    "popular_movies = movie_count_df.merge(\n",
    "    movies[['movieId', 'title']],\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Get the top 10 most-rated movies\n",
    "top10_popular = popular_movies.head(10)\n",
    "top10_popular.index = range(1, len(top10_popular) + 1)\n",
    "\n",
    "print(\"Top 10 Most Popular Movies:\")\n",
    "print(top10_popular[['title', 'num_ratings']])\n",
    "\n"
   ],
   "id": "a08846af8274c92d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Average Rating Recommender\n",
    "\n",
    "#Group DataFrame by movieId and count ratings.\n",
    "    #set correct path\n",
    "os.chdir(r\"C:\\Users\\Emmet\\PycharmProjects\\streaming-recs-project\")\n",
    "    #create dataframe from ratings and movies\n",
    "ratings = pd.read_csv('data/ml32/ratings.csv')\n",
    "movies = pd.read_csv('data/ml32/movies.csv')\n",
    "df = ratings.merge(movies, on='movieId', how='left')\n",
    "\n",
    "movie_stats = df.groupby('movieId')['rating'].agg(['mean','count']).reset_index()\n",
    "movie_stats.columns = ['movieId','avg_rating','num_rating']\n",
    "\n",
    "#sets minimum number of ratings to be considered\n",
    "min_rating = 50\n",
    "filtered_movies = movie_stats[movie_stats['num_rating'] >= min_rating]\n",
    "\n",
    "sorted_movies = filtered_movies.sort_values(by='avg_rating', ascending=False)\n",
    "\n",
    "avg_rating_recs = sorted_movies.merge(\n",
    "    movies[['movieId', 'title']],\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "top10_avg_rating = avg_rating_recs.head(10)\n",
    "top10_avg_rating.index = range(1, len(top10_avg_rating) + 1)\n",
    "print(top10_avg_rating[['title', 'avg_rating', 'num_rating']])\n"
   ],
   "id": "f867e34057b448d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:00:55.407906Z",
     "start_time": "2025-08-15T22:00:36.609521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#BUILD RECOMMENDER\n",
    "\n",
    "#create data frame\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\Emmet\\PycharmProjects\\streaming-recs-project\")\n",
    "dtypes = {\n",
    "    'userId': 'int32',\n",
    "    'movieId': 'int32',\n",
    "    'rating': 'float32',\n",
    "    'timestamp': 'int32',\n",
    "}\n",
    "df = pd.read_csv('data/ml32/ratings.csv', dtype=dtypes, low_memory=False)\n",
    "movies = pd.read_csv('data/ml32/movies.csv')\n",
    "\n",
    "#drop timestamp\n",
    "df.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "#create user-item rating matrix\n",
    "#To make sure the df isn't too big we're filtering down to the 500 most active users and most popular movies.\n",
    "\n",
    "active_users = df['userId'].value_counts().head(500).index\n",
    "popular_movies = df['movieId'].value_counts().head(500).index\n",
    "df_filtered = df[df['userId'].isin(active_users) & df['movieId'].isin(popular_movies)]\n",
    "\n",
    "#create new matrix\n",
    "user_item_matrix = df_filtered.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values = 'rating',\n",
    ")\n",
    "\n",
    "print(user_item_matrix.shape) #number of users and movies\n",
    "print(user_item_matrix.head(3)) # preview first 3 users\n",
    "\n",
    "\n"
   ],
   "id": "7233de29464d76c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n",
      "movieId  1       2       6       10      11      16      17      19      \\\n",
      "userId                                                                    \n",
      "28          4.0     3.0     3.0     3.0     5.0     3.0     4.0     NaN   \n",
      "188         4.0     4.0     5.0     NaN     3.0     5.0     2.5     3.5   \n",
      "265         5.0     4.0     NaN     4.0     NaN     4.0     NaN     NaN   \n",
      "\n",
      "movieId  21      25      ...  119145  122882  122886  122904  122912  134130  \\\n",
      "userId                   ...                                                   \n",
      "28          4.0     3.0  ...     4.0     5.0     3.5     4.0     3.5     5.0   \n",
      "188         4.5     2.5  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "265         3.5     NaN  ...     5.0     4.5     4.0     4.0     4.0     4.0   \n",
      "\n",
      "movieId  134853  148626  152081  164179  \n",
      "userId                                   \n",
      "28          4.5     5.0     4.0     4.0  \n",
      "188         NaN     NaN     NaN     NaN  \n",
      "265         NaN     5.0     NaN     5.0  \n",
      "\n",
      "[3 rows x 500 columns]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#compute item to item similarity\n",
    "\n",
    "user_item_filled = user_item_matrix.fillna(0)\n",
    "user_item_matrix = user_item_filled.T\n",
    "\n",
    "#cosine similarity\n",
    "item_similarity = cosine_similarity(user_item_matrix)\n",
    "item_similarity_df = user_item_matrix.corr(method='pearson', min_periods=10)\n",
    "\n"
   ],
   "id": "a69523fa4e5e540b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:04:39.947273Z",
     "start_time": "2025-08-15T22:04:39.922173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_similar_movies(movie_id, top_n=10):\n",
    "    similar_scores = item_similarity_df[movie_id].drop(movie_id)\n",
    "    similar_ids = similar_scores.sort_values(ascending=False).head(top_n).index\n",
    "\n",
    "    return movies[movies['movieId'].isin(similar_ids)][['title']]\n",
    "\n",
    "movie_marker = movies.loc[movies['title'] == 'Toy Story (1995)', 'movieId'].values[0]\n",
    "print(get_similar_movies(movie_marker, top_n=5))"
   ],
   "id": "e3bace5bd2f462d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        title\n",
      "359     Lion King, The (1994)\n",
      "3021       Toy Story 2 (1999)\n",
      "4781    Monsters, Inc. (2001)\n",
      "6259      Finding Nemo (2003)\n",
      "8248  Incredibles, The (2004)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:08:55.344418Z",
     "start_time": "2025-08-15T22:08:53.342713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#recommend movies to a specific user\n",
    "\n",
    "import random\n",
    "\n",
    "def recommend_for_user(user_id, user_item_matrix, item_similarity_df, top_n=10):\n",
    "    #get user rating\n",
    "    user_ratings = user_item_matrix.loc[user_id].dropna()\n",
    "\n",
    "\n",
    "    # Make sure we're using movie titles, not IDs\n",
    "    if not set(user_ratings.index).issubset(item_similarity_df.columns):\n",
    "        raise ValueError(\"Mismatch between user_item_matrix columns and similarity matrix.\")\n",
    "\n",
    "    #store scores for all candidate movies\n",
    "    scores = {}\n",
    "\n",
    "    for movie, rating, in user_ratings.items():\n",
    "        similar_movie = item_similarity_df[movie].drop(movie)\n",
    "\n",
    "        for similar_movie, similarity in similar_movie.items():\n",
    "            #only consider if user hasnt seen movie\n",
    "            if pd.isna(user_item_matrix.loc[user_id, similar_movie]):\n",
    "                scores[similar_movie] = scores.get(similar_movie, 0) + similarity*rating\n",
    "\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    ranked_with_titles = [(movies.loc[movies['movieId'] == mid, 'title'].values[0], score) for mid, score in ranked]\n",
    "\n",
    "    return ranked_with_titles\n",
    "\n",
    "\n",
    "\n",
    "#example use:\n",
    "\n",
    "user_id = random.choice(user_item_matrix.index.tolist()) # pick a user from your filtered dataset\n",
    "recommendations = recommend_for_user(user_id, user_item_matrix, item_similarity_df, top_n=5)\n",
    "\n",
    "print(f\"Top recommendations for user {user_id}:\")\n",
    "for title, score in recommendations:\n",
    "    print(f\"{title} (score: {score:.3f})\")\n",
    "\n"
   ],
   "id": "e1994b1f9eff4443",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for user 133464:\n",
      "Toy Story (1995) (score: 227.875)\n",
      "Toy Story 2 (1999) (score: 216.645)\n",
      "Star Trek (2009) (score: 209.812)\n",
      "X2: X-Men United (2003) (score: 201.474)\n",
      "Erin Brockovich (2000) (score: 200.662)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:18:25.886908Z",
     "start_time": "2025-08-15T22:18:05.831295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# EVALUATE AND CHECK RECOMMENDATIONS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#split original ratings into train and test sets\n",
    "train_df, test_df = train_test_split(df_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train test split: {len(train_df)} ratings\")\n",
    "print(f\"Test set: {len(test_df)} ratings\")\n",
    "\n",
    "train_matrix = train_df.pivot_table(\n",
    "    index='userId',\n",
    "    columns='movieId',\n",
    "    values='rating'\n",
    ")\n",
    "\n",
    "#fill NaN with 0 for similarity calculation\n",
    "train_matrix_filled = train_matrix.fillna(0)\n",
    "\n",
    "item_similarity = cosine_similarity(train_matrix_filled.T)\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=train_matrix_filled.columns,\n",
    "    columns=train_matrix_filled.columns\n",
    ")\n",
    "\n",
    "def predict_rating(user_id, movie_id, user_item_matrix, item_similarity_df):\n",
    "    # Ratings the user has made\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "\n",
    "    # Similarities for the target movie\n",
    "    similarities = item_similarity_df[movie_id]\n",
    "\n",
    "    # Only consider movies the user has rated\n",
    "    rated_mask = ~user_ratings.isna()\n",
    "    relevant_ratings = user_ratings[rated_mask]\n",
    "    relevant_similarities = similarities[rated_mask]\n",
    "\n",
    "    if relevant_similarities.sum() == 0:\n",
    "        return None  # Can't make prediction\n",
    "\n",
    "    return (relevant_ratings * relevant_similarities).sum() / relevant_similarities.sum()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    pred = predict_rating(row['userId'], row['movieId'], train_matrix, item_similarity_df)\n",
    "    if pred is not None:\n",
    "        predictions.append(pred)\n",
    "        actuals.append(row['rating'])\n",
    "\n",
    "rmse = sqrt(mean_squared_error(actuals, predictions))\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "fb0f70d8d7e70c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test split: 155327 ratings\n",
      "Test set: 38832 ratings\n",
      "RMSE: 0.9125\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:20:21.825999Z",
     "start_time": "2025-08-15T22:20:19.965358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_user = random.choice(train_matrix.index.tolist())\n",
    "recs = recommend_for_user(sample_user, train_matrix, item_similarity_df, top_n=5)\n",
    "\n",
    "print(f\"Top recommendations for user {sample_user}:\")\n",
    "for title, score in recs:\n",
    "    print(f\"{title} (score: {score:.3f})\")"
   ],
   "id": "bb228339b9348e39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for user 78213:\n",
      "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) (score: 816.502)\n",
      "Twelve Monkeys (a.k.a. 12 Monkeys) (1995) (score: 802.570)\n",
      "Star Wars: Episode IV - A New Hope (1977) (score: 798.314)\n",
      "Pulp Fiction (1994) (score: 796.558)\n",
      "Seven (a.k.a. Se7en) (1995) (score: 795.889)\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
